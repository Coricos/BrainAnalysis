{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from package.dl_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2D Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = []\n",
    "lab = pd.read_csv('./dataset/label.csv', sep=';', index_col=0)\n",
    "msk = np.load('./models/row_mask.npy')[:len(lab)]\n",
    "with h5py.File('./dataset/train.h5', 'r') as dtb:\n",
    "    for key in ['eeg_{}'.format(dim) for dim in range(1, 5)]:\n",
    "        tmp = dtb[key].value[msk]\n",
    "        tmp = np.asarray([interpolate(ele, size=750) for ele in tmp])\n",
    "        eeg.append(tmp.reshape(tmp.shape[0], 1, tmp.shape[1]))\n",
    "eeg = np.concatenate(tuple(eeg), axis=1)\n",
    "lab = lab[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "idx = np.random.choice(np.arange(eeg.shape[0]))\n",
    "for i in range(4):\n",
    "    plt.subplot(4,1,i+1)\n",
    "    plt.plot(eeg[idx,i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,2))\n",
    "idx = np.random.choice(np.arange(eeg.shape[0]))\n",
    "sns.heatmap(eeg[idx], cmap='Greys')\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "input_img = Input(shape=(4, 750, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(encoded._keras_shape)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 3))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='tanh', padding='same')(x)\n",
    "print(decoded._keras_shape)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_t, i_v = train_test_split(np.arange(len(eeg)), shuffle=True, test_size=0.3)\n",
    "x_t, x_v = eeg[i_t].reshape((len(i_t), 4, 750, 1)), eeg[i_v].reshape((len(i_v), 4, 750, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_t, x_t, epochs=10, batch_size=128, shuffle=True, validation_data=(x_v, x_v), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDA Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landscapes(dig, m_n=None, m_x=None, nb_landscapes=10, num_points=100, graph=False):\n",
    "\n",
    "    # Automated construction of the landscapes\n",
    "    # n_landscapes refers to the amount of landscapes to build\n",
    "    # num_points refers to the amount of points to get as output\n",
    "    # m_n, m_x refer to the extrema for discretization\n",
    "    def build_landscapes(dig, nb_landscapes, num_points, m_n, m_x):\n",
    "\n",
    "        # Prepares the discretization\n",
    "        lcd = np.zeros((nb_landscapes, num_points))\n",
    "\n",
    "        # Observe whether absolute or relative\n",
    "        if m_n and m_x:\n",
    "            stp = np.linspace(m_n, m_x, num=num_points)\n",
    "        else:\n",
    "            m_n, m_x = np.min(dig), np.max(dig)\n",
    "            stp = np.linspace(m_n, m_x, num=num_points)\n",
    "\n",
    "        # Use the triangular functions\n",
    "        for idx, ele in enumerate(stp):\n",
    "            val = []\n",
    "            for pair in dig:\n",
    "                b, d = pair[0], pair[1]\n",
    "                if (d+b)/2.0 <= ele <= d: val.append(d - ele)\n",
    "                elif  b <= ele <= (d+b)/2.0: val.append(ele - b)\n",
    "            val.sort(reverse=True)\n",
    "            val = np.asarray(val)\n",
    "            for j in range(nb_landscapes):\n",
    "                if (j < len(val)): lcd[j, idx] = val[j]\n",
    "\n",
    "        return lcd\n",
    "\n",
    "    # Computes the persistent landscapes for both diagrams\n",
    "    dig = np.asarray([[ele[0], ele[1]] for ele in dig if ele[1] < np.inf])\n",
    "    ldc = build_landscapes(dig, nb_landscapes, num_points, m_n, m_x)\n",
    "\n",
    "    # Display landscapes if necessary\n",
    "    if graph:\n",
    "        plt.figure(figsize=(18,2))\n",
    "        plt.title('Persistent Landscapes')\n",
    "        for ele in ldc: plt.plot(ele)\n",
    "        plt.show()\n",
    "\n",
    "    return ldc        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betti_curves(dig, m_n=None, m_x=None, num_points=100, graph=False):\n",
    "\n",
    "    # Aims at barcode discretization\n",
    "    def functionize(val, descriptor):\n",
    "\n",
    "        # Temporary function\n",
    "        def dirichlet(x):\n",
    "            return 1 if (x > descriptor[0]) and (x < descriptor[1]) else 0\n",
    "\n",
    "        # Vectorized function\n",
    "        fun = np.vectorize(dirichlet)\n",
    "\n",
    "        return fun(val)\n",
    "\n",
    "    # Compute persistence\n",
    "    res = np.zeros(num_points)\n",
    "    dig = np.asarray([[ele[0], ele[1]] for ele in dig if ele[1] < np.inf])\n",
    "\n",
    "    if m_n and m_x: \n",
    "        val = np.linspace(m_n, m_x, num=num_points)\n",
    "    else:\n",
    "        m_n, m_x = np.min(dig), np.max(dig)\n",
    "        val = np.linspace(m_n, m_x, num=num_points)\n",
    "\n",
    "    for ele in dig: res += functionize(val, ele)\n",
    "\n",
    "    # Memory efficiency\n",
    "    del dig, val\n",
    "\n",
    "    if graph:\n",
    "        plt.figure(figsize=(18,2))\n",
    "        plt.plot(res, label='Sublevel Filtration - Betti Curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripser import Rips\n",
    "\n",
    "rips = Rips(verbose=False, maxdim=1)\n",
    "diagrams = rips.fit_transform(tmp.T)\n",
    "\n",
    "_ = betti_curves(diagrams[1], graph=True)\n",
    "_ = landscapes(diagrams[1], graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
